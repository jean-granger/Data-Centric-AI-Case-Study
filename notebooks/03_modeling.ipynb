{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76954d3-7bd7-4aea-9108-3f75710b0e08",
   "metadata": {},
   "source": [
    "# 03 - Modeling: Baseline vs Improved\n",
    "Compare performance using raw vs cleaned dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed05cc0-9275-4607-a514-2bb8c4c1f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "from src.train import train_and_eval\n",
    "\n",
    "raw_path = \"../data/raw/heart.csv\"\n",
    "proc_path = \"../data/processed/heart_processed.csv\"\n",
    "\n",
    "df_raw = pd.read_csv(raw_path)\n",
    "df_proc = pd.read_csv(proc_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ac6f77-50cf-4569-a974-8445bfa2ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_Xy(df, target_col='target'):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    return X.select_dtypes(include=['int64','float64']), y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec7abb7-5a81-471b-b3dd-487d964b7909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33         4\n",
      "           1       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.38      0.38      0.33         6\n",
      "weighted avg       0.42      0.33      0.33         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_raw, y_raw = prepare_Xy(df_raw)\n",
    "clf_raw, X_test_raw, y_test_raw, preds_raw = train_and_eval(X_raw, y_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7c4c67-7e48-4502-a242-9db83d935a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.25      0.33         4\n",
      "         1.0       0.25      0.50      0.33         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.38      0.38      0.33         6\n",
      "weighted avg       0.42      0.33      0.33         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_proc, y_proc = prepare_Xy(df_proc)\n",
    "clf_proc, X_test_proc, y_test_proc, preds_proc = train_and_eval(X_proc, y_proc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f2f339-484e-4eae-86eb-b18396110628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.3333333333333333\n",
      "Processed accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Baseline accuracy:\", accuracy_score(y_test_raw, preds_raw))\n",
    "print(\"Processed accuracy:\", accuracy_score(y_test_proc, preds_proc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96874366-a16d-4b11-b24d-d213199d109b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Modeling Results\n",
       "- Baseline accuracy: **0.333**\n",
       "- Processed accuracy: **0.333**\n",
       "- On this small sample, results are similar because there were no missing values or categorical encodings needed.\n",
       "- In larger datasets, data cleaning usually improves stability and metrics.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "acc_raw = accuracy_score(y_test_raw, preds_raw)\n",
    "acc_proc = accuracy_score(y_test_proc, preds_proc)\n",
    "\n",
    "md = f\"\"\"\n",
    "### Modeling Results\n",
    "- Baseline accuracy: **{acc_raw:.3f}**\n",
    "- Processed accuracy: **{acc_proc:.3f}**\n",
    "- On this small sample, results are similar because there were no missing values or categorical encodings needed.\n",
    "- In larger datasets, data cleaning usually improves stability and metrics.\n",
    "\"\"\"\n",
    "display(Markdown(md))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
